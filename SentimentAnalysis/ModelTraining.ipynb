{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1c8e50-c016-487c-9bf2-ec079f0c86f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0+cu128\n",
      "CUDA version: 12.8\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81837bd7-cc0c-498d-b300-4efd3ef9a68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: colorama in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacondanav\\anacondanavprogram\\envs\\sentimentanalysis-bert\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0ece0b-5896-40dc-9113-6fbe82fcfa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3600000/3600000 [00:03<00:00, 1032420.98 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400000/400000 [00:00<00:00, 1025640.12 examples/s]\n",
      "D:\\AnacondaNav\\AnacondaNavProgram\\envs\\SentimentAnalysis-bert\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bgari\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000000/1000000 [02:44<00:00, 6082.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300000/300000 [00:48<00:00, 6165.38 examples/s]\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9091/9091 [2:47:59<00:00,  1.11s/it, loss=0.159]   \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2728/2728 [17:58<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 â–¶ Acc: 0.9639 | Precision: 0.9748 | Recall: 0.9526 | F1: 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9091/9091 [2:46:58<00:00,  1.10s/it, loss=0.0967]   \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2728/2728 [18:03<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 â–¶ Acc: 0.9670 | Precision: 0.9663 | Recall: 0.9679 | F1: 0.9671\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (Run only once)\n",
    "# pip install transformers datasets scikit-learn torch tqdm\n",
    "\n",
    "# ----------------------\n",
    "# Imports\n",
    "# ----------------------\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ----------------------\n",
    "# Set device\n",
    "# ----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "# ----------------------\n",
    "# Load & Subsample Dataset\n",
    "# ----------------------\n",
    "dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Shuffle and subset\n",
    "train_subset = dataset[\"train\"].shuffle(seed=42).select(range(1_000_000))\n",
    "test_subset  = dataset[\"test\"].shuffle(seed=42).select(range(300_000))\n",
    "\n",
    "# ----------------------\n",
    "# Tokenization\n",
    "# ----------------------\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    texts = [t + \". \" + c for t, c in zip(batch[\"title\"], batch[\"content\"])]\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_subset = train_subset.map(tokenize_batch, batched=True, remove_columns=[\"title\", \"content\"])\n",
    "test_subset  = test_subset.map(tokenize_batch,  batched=True, remove_columns=[\"title\", \"content\"])\n",
    "\n",
    "train_subset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_subset.set_format(\"torch\",  columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_ds = train_subset\n",
    "val_ds   = test_subset\n",
    "\n",
    "# ----------------------\n",
    "# DataLoaders\n",
    "# ----------------------\n",
    "batch_size = 110  # adjust if memory is low\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size)\n",
    "\n",
    "# ----------------------\n",
    "# Model, Optimizer, Scheduler\n",
    "# ----------------------\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "total_steps = len(train_loader) * epochs  # epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=total_steps // 10,\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Training Loop\n",
    "# ----------------------\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\")\n",
    "    for batch in train_pbar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        masks     = batch[\"attention_mask\"].to(device)\n",
    "        labels    = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # ----------------------\n",
    "    # Validation\n",
    "    # ----------------------\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "        with torch.no_grad():\n",
    "            logits = model(\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                attention_mask=batch[\"attention_mask\"].to(device)\n",
    "            ).logits\n",
    "        preds = logits.argmax(dim=-1).cpu().tolist()\n",
    "        labels = batch[\"label\"].cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "    print(f\"Epoch {epoch+1} â–¶ Acc: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae74301-cf2e-46e6-9256-2c976418d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to 'saved_bert_sentiment_model/'\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Save Model\n",
    "# ----------------------\n",
    "model.save_pretrained(\"saved_bert_sentiment_model\")\n",
    "tokenizer.save_pretrained(\"saved_bert_sentiment_model\")\n",
    "print(\"âœ… Model saved to 'saved_bert_sentiment_model/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6135e2e6-35f8-450b-a875-76fb79618059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a review (or type 'exit'):  i hate it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Negative ðŸ˜ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a review (or type 'exit'):  good but bad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Negative ðŸ˜ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a review (or type 'exit'):  good product\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Positive ðŸ˜Š\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a review (or type 'exit'):  I am writing to formally complain about my recent purchase of an iPhone 16 from online on Amazon. I received the item on the same day of purchase, but upon unboxing, I noticed that the iPhone came in a mismatched (muddled) box. When I powered it on, the phone was stuck on the â€œHelloâ€ screen, repeatedly displaying â€œHelloâ€ in multiple languages. It was completely unresponsiveâ€”none of the buttons, including the power and volume buttons, were functioning.  After approximately five hours, the battery finally drained, and the phone shut down. However, after restarting, the same issue persisted, with the device stuck on the â€œHelloâ€ screen again.  I contacted Amazonâ€™s support team, who advised me to reach out to Apple Support. Apple Support suggested some troubleshooting steps, but none resolved the issue. Ultimately, they advised me to visit an Apple-authorized service center for a software reinstallationâ€”on a brand-new phone.  I then had to travel 5 km to a Maple (Apple-authorized) service center, where they reinstalled the software. The process took about 45â€“50 minutes, finally making the phone functional.  I am extremely disappointed with this experience. After purchasing a costly device, I suffered an entire day of inconvenience due to the sellerâ€™s inefficiency or the companyâ€™s negligence in quality control. This is unacceptable, especially for a premium product.  Previously, I had purchased an iPhone 15 online without any issues, but this time, the experience was frustrating and disappointing. I strongly urge you to take action against this seller for supplying what appears to be old or improperly stored stock.  I request appropriate compensation for the inconvenience and mental stress caused. Additionally, I advise other customers to be cautious when purchasing from this seller.  I hope Amazon takes this matter seriously and ensures such incidents do not happen again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Negative ðŸ˜ \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a review (or type 'exit'):  Very light and better than previous versions. Or letâ€™s say everything is great but Iâ€™m little disappointed by the camera, I believe the best camera they had was with 11, after all my upgrades and finally to 16, I didnâ€™t find such stable and best in class camera. AI in iOS is still evolving and not yet that great.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Positive ðŸ˜Š\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a review (or type 'exit'):  exit\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Manual Input Prediction\n",
    "# ----------------------\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "    return \"Positive ðŸ˜Š\" if pred == 1 else \"Negative ðŸ˜ \"\n",
    "\n",
    "# Example\n",
    "while True:\n",
    "    user_input = input(\"Enter a review (or type 'exit'): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    result = predict_sentiment(user_input)\n",
    "    print(\"Prediction:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e6bb87-ae59-4295-a939-b35531cc5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c49bd3-845c-463f-ace9-ab7f8e3eb490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CUDA)",
   "language": "python",
   "name": "sentimentanalysis-bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
